{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911be1ed",
   "metadata": {},
   "source": [
    "# Linear Algebra for Data Science\n",
    "\n",
    "## Chapter 4: Vecctor applications\n",
    "\n",
    "https://github.com/mikexcohen/LinAlg4DataScience/blob/main/LA4DS_ch04.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c067b3",
   "metadata": {},
   "source": [
    "### Correlation and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e78b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float64(0.9819805060619659), np.float64(0.9968895725584537))\n",
      "[[1.         0.98198051]\n",
      " [0.98198051 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exercise 4-1\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([3,5,9])\n",
    "\n",
    "def corr_and_cosine(x, y):\n",
    "    x_bar = x.mean()\n",
    "    y_bar = y.mean()\n",
    "\n",
    "    # Cosine\n",
    "    num = np.dot(x,y)\n",
    "    den = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "    cosine_corr = num/den\n",
    "\n",
    "    # Pearson correlation\n",
    "    xm = x - x.mean()\n",
    "    ym = y - y.mean()\n",
    "    numm = np.dot(xm, ym)\n",
    "    denm = np.linalg.norm(xm) * np.linalg.norm(ym)\n",
    "    p = numm /denm\n",
    "\n",
    "    return p, cosine_corr\n",
    "\n",
    "\n",
    "print(corr_and_cosine(a, b))\n",
    "print(np.corrcoef(a,b))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7be946a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without mean-centering (should differ):\n",
      "[-0.153  -0.1728]\n",
      " \n",
      "With mean-centering (should be the same):\n",
      "[-0.153 -0.153]\n"
     ]
    }
   ],
   "source": [
    "# compare r and c without mean-centering\n",
    "a = np.random.randn(15) + 10 # note the offset!\n",
    "b = np.random.randn(15)\n",
    "\n",
    "# mean-center\n",
    "aNoMean = a - np.mean(a)\n",
    "bNoMean = b - np.mean(b)\n",
    "\n",
    "# show the results with and without mean-centering\n",
    "print('Without mean-centering (should differ):')\n",
    "print( np.round(corr_and_cosine(a,b),4) )\n",
    "print(' ')\n",
    "\n",
    "print('With mean-centering (should be the same):')\n",
    "print( np.round(corr_and_cosine(aNoMean,bNoMean),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b01f2145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 4-2\n",
    "a = np.arange(4, dtype=float)\n",
    "offsets = np.arange(-50,51)\n",
    "\n",
    "# initialize the results\n",
    "results = np.zeros((len(offsets), 2))\n",
    "\n",
    "for i in range(len(offsets)):\n",
    "    b = a + offsets[i]\n",
    "    results[i, :] = corr_and_cosine(a, b)\n",
    "\n",
    "h = plt.plot(offsets, results)\n",
    "h[0].set_color('k')\n",
    "h[0].set_marker('o')\n",
    "h[1].set_color([0.7,0.7,0.7])\n",
    "h[1].set_marker('o')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55ec4a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m pearsonr(x, y, *, alternative=\u001b[33m'two-sided'\u001b[39m, method=\u001b[38;5;28;01mNone\u001b[39;00m, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Pearson correlation coefficient and p-value for testing non-correlation.\n",
      "\n",
      "The Pearson correlation coefficient [1]_ measures the linear relationship\n",
      "between two datasets. Like other correlation\n",
      "coefficients, this one varies between -1 and +1 with 0 implying no\n",
      "correlation. Correlations of -1 or +1 imply an exact linear relationship.\n",
      "Positive correlations imply that as x increases, so does y. Negative\n",
      "correlations imply that as x increases, y decreases.\n",
      "\n",
      "This function also performs a test of the null hypothesis that the\n",
      "distributions underlying the samples are uncorrelated and normally\n",
      "distributed. (See Kowalski [3]_\n",
      "for a discussion of the effects of non-normality of the input on the\n",
      "distribution of the correlation coefficient.)\n",
      "The p-value roughly indicates the probability of an uncorrelated system\n",
      "producing datasets that have a Pearson correlation at least as extreme\n",
      "as the one computed from these datasets.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x : array_like\n",
      "    Input array.\n",
      "y : array_like\n",
      "    Input array.\n",
      "axis : int or None, default\n",
      "    Axis along which to perform the calculation. Default is 0.\n",
      "    If None, ravel both arrays before performing the calculation.\n",
      "    \n",
      "    .. versionadded:: 1.14.0\n",
      "alternative : {'two-sided', 'greater', 'less'}, optional\n",
      "    Defines the alternative hypothesis. Default is 'two-sided'.\n",
      "    The following options are available:\n",
      "    \n",
      "    * 'two-sided': the correlation is nonzero\n",
      "    * 'less': the correlation is negative (less than zero)\n",
      "    * 'greater':  the correlation is positive (greater than zero)\n",
      "    \n",
      "    .. versionadded:: 1.9.0\n",
      "method : ResamplingMethod, optional\n",
      "    Defines the method used to compute the p-value. If `method` is an\n",
      "    instance of `PermutationMethod`/`MonteCarloMethod`, the p-value is\n",
      "    computed using\n",
      "    `scipy.stats.permutation_test`/`scipy.stats.monte_carlo_test` with the\n",
      "    provided configuration options and other appropriate settings.\n",
      "    Otherwise, the p-value is computed as documented in the notes.\n",
      "    \n",
      "    .. versionadded:: 1.11.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "result : `~scipy.stats._result_classes.PearsonRResult`\n",
      "    An object with the following attributes:\n",
      "    \n",
      "    statistic : float\n",
      "        Pearson product-moment correlation coefficient.\n",
      "    pvalue : float\n",
      "        The p-value associated with the chosen alternative.\n",
      "    \n",
      "    The object has the following method:\n",
      "    \n",
      "    confidence_interval(confidence_level, method)\n",
      "        This computes the confidence interval of the correlation\n",
      "        coefficient `statistic` for the given confidence level.\n",
      "        The confidence interval is returned in a ``namedtuple`` with\n",
      "        fields `low` and `high`. If `method` is not provided, the\n",
      "        confidence interval is computed using the Fisher transformation\n",
      "        [1]_. If `method` is an instance of `BootstrapMethod`, the\n",
      "        confidence interval is computed using `scipy.stats.bootstrap` with\n",
      "        the provided configuration options and other appropriate settings.\n",
      "        In some cases, confidence limits may be NaN due to a degenerate\n",
      "        resample, and this is typical for very small samples (~6\n",
      "        observations).\n",
      "\n",
      "Raises\n",
      "------\n",
      "ValueError\n",
      "    If `x` and `y` do not have length at least 2.\n",
      "\n",
      "Warns\n",
      "-----\n",
      "`~scipy.stats.ConstantInputWarning`\n",
      "    Raised if an input is a constant array.  The correlation coefficient\n",
      "    is not defined in this case, so ``np.nan`` is returned.\n",
      "`~scipy.stats.NearConstantInputWarning`\n",
      "    Raised if an input is \"nearly\" constant.  The array ``x`` is considered\n",
      "    nearly constant if ``norm(x - mean(x)) < 1e-13 * abs(mean(x))``.\n",
      "    Numerical errors in the calculation ``x - mean(x)`` in this case might\n",
      "    result in an inaccurate calculation of r.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "\n",
      ":func:`spearmanr`\n",
      "    Spearman rank-order correlation coefficient.\n",
      ":func:`kendalltau`\n",
      "    Kendall's tau, a correlation measure for ordinal data.\n",
      ":ref:`hypothesis_pearsonr`\n",
      "    Extended example\n",
      "\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The correlation coefficient is calculated as follows:\n",
      "\n",
      ".. math::\n",
      "\n",
      "    r = \\frac{\\sum (x - m_x) (y - m_y)}\n",
      "             {\\sqrt{\\sum (x - m_x)^2 \\sum (y - m_y)^2}}\n",
      "\n",
      "where :math:`m_x` is the mean of the vector x and :math:`m_y` is\n",
      "the mean of the vector y.\n",
      "\n",
      "Under the assumption that x and y are drawn from\n",
      "independent normal distributions (so the population correlation coefficient\n",
      "is 0), the probability density function of the sample correlation\n",
      "coefficient r is ([1]_, [2]_):\n",
      "\n",
      ".. math::\n",
      "    f(r) = \\frac{{(1-r^2)}^{n/2-2}}{\\mathrm{B}(\\frac{1}{2},\\frac{n}{2}-1)}\n",
      "\n",
      "where n is the number of samples, and B is the beta function.  This\n",
      "is sometimes referred to as the exact distribution of r.  This is\n",
      "the distribution that is used in `pearsonr` to compute the p-value when\n",
      "the `method` parameter is left at its default value (None).\n",
      "The distribution is a beta distribution on the interval [-1, 1],\n",
      "with equal shape parameters a = b = n/2 - 1.  In terms of SciPy's\n",
      "implementation of the beta distribution, the distribution of r is::\n",
      "\n",
      "    dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
      "\n",
      "The default p-value returned by `pearsonr` is a two-sided p-value. For a\n",
      "given sample with correlation coefficient r, the p-value is\n",
      "the probability that abs(r') of a random sample x' and y' drawn from\n",
      "the population with zero correlation would be greater than or equal\n",
      "to abs(r). In terms of the object ``dist`` shown above, the p-value\n",
      "for a given r and length n can be computed as::\n",
      "\n",
      "    p = 2*dist.cdf(-abs(r))\n",
      "\n",
      "When n is 2, the above continuous distribution is not well-defined.\n",
      "One can interpret the limit of the beta distribution as the shape\n",
      "parameters a and b approach a = b = 0 as a discrete distribution with\n",
      "equal probability masses at r = 1 and r = -1.  More directly, one\n",
      "can observe that, given the data x = [x1, x2] and y = [y1, y2], and\n",
      "assuming x1 != x2 and y1 != y2, the only possible values for r are 1\n",
      "and -1.  Because abs(r') for any sample x' and y' with length 2 will\n",
      "be 1, the two-sided p-value for a sample of length 2 is always 1.\n",
      "\n",
      "For backwards compatibility, the object that is returned also behaves\n",
      "like a tuple of length two that holds the statistic and the p-value.\n",
      "\n",
      "`pearsonr` has experimental support for Python Array API Standard compatible\n",
      "backends in addition to NumPy. Please consider testing these features\n",
      "by setting an environment variable ``SCIPY_ARRAY_API=1`` and providing\n",
      "CuPy, PyTorch, JAX, or Dask arrays as array arguments. The following\n",
      "combinations of backend and device (or other capability) are supported.\n",
      "\n",
      "====================  ====================  ====================\n",
      "Library               CPU                   GPU\n",
      "====================  ====================  ====================\n",
      "NumPy                 ✅                     n/a                 \n",
      "CuPy                  n/a                   ✅                   \n",
      "PyTorch               ✅                     ⛔                   \n",
      "JAX                   ⚠️ no JIT             ⛔                   \n",
      "Dask                  ⚠️ computes graph     n/a                 \n",
      "====================  ====================  ====================\n",
      "\n",
      "See :ref:`dev-arrayapi` for more information.\n",
      "\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] \"Pearson correlation coefficient\", Wikipedia,\n",
      "       https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
      ".. [2] Student, \"Probable error of a correlation coefficient\",\n",
      "       Biometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.\n",
      ".. [3] C. J. Kowalski, \"On the Effects of Non-Normality on the Distribution\n",
      "       of the Sample Product-Moment Correlation Coefficient\"\n",
      "       Journal of the Royal Statistical Society. Series C (Applied\n",
      "       Statistics), Vol. 21, No. 1 (1972), pp. 1-12.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from scipy import stats\n",
      ">>> x, y = [1, 2, 3, 4, 5, 6, 7], [10, 9, 2.5, 6, 4, 3, 2]\n",
      ">>> res = stats.pearsonr(x, y)\n",
      ">>> res\n",
      "PearsonRResult(statistic=-0.828503883588428, pvalue=0.021280260007523286)\n",
      "\n",
      "To perform an exact permutation version of the test:\n",
      "\n",
      ">>> rng = np.random.default_rng(7796654889291491997)\n",
      ">>> method = stats.PermutationMethod(n_resamples=np.inf, random_state=rng)\n",
      ">>> stats.pearsonr(x, y, method=method)\n",
      "PearsonRResult(statistic=-0.828503883588428, pvalue=0.028174603174603175)\n",
      "\n",
      "To perform the test under the null hypothesis that the data were drawn from\n",
      "*uniform* distributions:\n",
      "\n",
      ">>> method = stats.MonteCarloMethod(rvs=(rng.uniform, rng.uniform))\n",
      ">>> stats.pearsonr(x, y, method=method)\n",
      "PearsonRResult(statistic=-0.828503883588428, pvalue=0.0188)\n",
      "\n",
      "To produce an asymptotic 90% confidence interval:\n",
      "\n",
      ">>> res.confidence_interval(confidence_level=0.9)\n",
      "ConfidenceInterval(low=-0.9644331982722841, high=-0.3460237473272273)\n",
      "\n",
      "And for a bootstrap confidence interval:\n",
      "\n",
      ">>> method = stats.BootstrapMethod(method='BCa', rng=rng)\n",
      ">>> res.confidence_interval(confidence_level=0.9, method=method)\n",
      "ConfidenceInterval(low=-0.9983163756488651, high=-0.22771001702132443)  # may vary\n",
      "\n",
      "If N-dimensional arrays are provided, multiple tests are performed in a\n",
      "single call according to the same conventions as most `scipy.stats` functions:\n",
      "\n",
      ">>> rng = np.random.default_rng(2348246935601934321)\n",
      ">>> x = rng.standard_normal((8, 15))\n",
      ">>> y = rng.standard_normal((8, 15))\n",
      ">>> stats.pearsonr(x, y, axis=0).statistic.shape  # between corresponding columns\n",
      "(15,)\n",
      ">>> stats.pearsonr(x, y, axis=1).statistic.shape  # between corresponding rows\n",
      "(8,)\n",
      "\n",
      "To perform all pairwise comparisons between slices of the arrays,\n",
      "use standard NumPy broadcasting techniques. For instance, to compute the\n",
      "correlation between all pairs of rows:\n",
      "\n",
      ">>> stats.pearsonr(x[:, np.newaxis, :], y, axis=-1).statistic.shape\n",
      "(8, 8)\n",
      "\n",
      "There is a linear dependence between x and y if y = a + b*x + e, where\n",
      "a,b are constants and e is a random error term, assumed to be independent\n",
      "of x. For simplicity, assume that x is standard normal, a=0, b=1 and let\n",
      "e follow a normal distribution with mean zero and standard deviation s>0.\n",
      "\n",
      ">>> rng = np.random.default_rng()\n",
      ">>> s = 0.5\n",
      ">>> x = stats.norm.rvs(size=500, random_state=rng)\n",
      ">>> e = stats.norm.rvs(scale=s, size=500, random_state=rng)\n",
      ">>> y = x + e\n",
      ">>> stats.pearsonr(x, y).statistic\n",
      "0.9001942438244763\n",
      "\n",
      "This should be close to the exact value given by\n",
      "\n",
      ">>> 1/np.sqrt(1 + s**2)\n",
      "0.8944271909999159\n",
      "\n",
      "For s=0.5, we observe a high level of correlation. In general, a large\n",
      "variance of the noise reduces the correlation, while the correlation\n",
      "approaches one as the variance of the error goes to zero.\n",
      "\n",
      "It is important to keep in mind that no correlation does not imply\n",
      "independence unless (x, y) is jointly normal. Correlation can even be zero\n",
      "when there is a very simple dependence structure: if X follows a\n",
      "standard normal distribution, let y = abs(x). Note that the correlation\n",
      "between x and y is zero. Indeed, since the expectation of x is zero,\n",
      "cov(x, y) = E[x*y]. By definition, this equals E[x*abs(x)] which is zero\n",
      "by symmetry. The following lines of code illustrate this observation:\n",
      "\n",
      ">>> y = np.abs(x)\n",
      ">>> stats.pearsonr(x, y)\n",
      "PearsonRResult(statistic=-0.05444919272687482, pvalue=0.22422294836207743)\n",
      "\n",
      "A non-zero correlation coefficient can be misleading. For example, if X has\n",
      "a standard normal distribution, define y = x if x < 0 and y = 0 otherwise.\n",
      "A simple calculation shows that corr(x, y) = sqrt(2/Pi) = 0.797...,\n",
      "implying a high level of correlation:\n",
      "\n",
      ">>> y = np.where(x < 0, x, 0)\n",
      ">>> stats.pearsonr(x, y)\n",
      "PearsonRResult(statistic=0.861985781588, pvalue=4.813432002751103e-149)\n",
      "\n",
      "This is unintuitive since there is no dependence of x and y if x is larger\n",
      "than zero which happens in about half of the cases if we sample x and y.\n",
      "\n",
      "For a more detailed example, see :ref:`hypothesis_pearsonr`.\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "@xp_capabilities(cpu_only=\u001b[38;5;28;01mTrue\u001b[39;00m, exceptions=[\u001b[33m'cupy'\u001b[39m],\n",
      "                 jax_jit=\u001b[38;5;28;01mFalse\u001b[39;00m, allow_dask_compute=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m pearsonr(x, y, *, alternative=\u001b[33m'two-sided'\u001b[39m, method=\u001b[38;5;28;01mNone\u001b[39;00m, axis=\u001b[32m0\u001b[39m):\n",
      "    \u001b[33mr\"\"\"\u001b[39m\n",
      "\u001b[33m    Pearson correlation coefficient and p-value for testing non-correlation.\u001b[39m\n",
      "\n",
      "\u001b[33m    The Pearson correlation coefficient [1]_ measures the linear relationship\u001b[39m\n",
      "\u001b[33m    between two datasets. Like other correlation\u001b[39m\n",
      "\u001b[33m    coefficients, this one varies between -1 and +1 with 0 implying no\u001b[39m\n",
      "\u001b[33m    correlation. Correlations of -1 or +1 imply an exact linear relationship.\u001b[39m\n",
      "\u001b[33m    Positive correlations imply that as x increases, so does y. Negative\u001b[39m\n",
      "\u001b[33m    correlations imply that as x increases, y decreases.\u001b[39m\n",
      "\n",
      "\u001b[33m    This function also performs a test of the null hypothesis that the\u001b[39m\n",
      "\u001b[33m    distributions underlying the samples are uncorrelated and normally\u001b[39m\n",
      "\u001b[33m    distributed. (See Kowalski [3]_\u001b[39m\n",
      "\u001b[33m    for a discussion of the effects of non-normality of the input on the\u001b[39m\n",
      "\u001b[33m    distribution of the correlation coefficient.)\u001b[39m\n",
      "\u001b[33m    The p-value roughly indicates the probability of an uncorrelated system\u001b[39m\n",
      "\u001b[33m    producing datasets that have a Pearson correlation at least as extreme\u001b[39m\n",
      "\u001b[33m    as the one computed from these datasets.\u001b[39m\n",
      "\n",
      "\u001b[33m    Parameters\u001b[39m\n",
      "\u001b[33m    ----------\u001b[39m\n",
      "\u001b[33m    x : array_like\u001b[39m\n",
      "\u001b[33m        Input array.\u001b[39m\n",
      "\u001b[33m    y : array_like\u001b[39m\n",
      "\u001b[33m        Input array.\u001b[39m\n",
      "\u001b[33m    axis : int or None, default\u001b[39m\n",
      "\u001b[33m        Axis along which to perform the calculation. Default is 0.\u001b[39m\n",
      "\u001b[33m        If None, ravel both arrays before performing the calculation.\u001b[39m\n",
      "\n",
      "\u001b[33m        .. versionadded:: 1.14.0\u001b[39m\n",
      "\u001b[33m    alternative : {'two-sided', 'greater', 'less'}, optional\u001b[39m\n",
      "\u001b[33m        Defines the alternative hypothesis. Default is 'two-sided'.\u001b[39m\n",
      "\u001b[33m        The following options are available:\u001b[39m\n",
      "\n",
      "\u001b[33m        * 'two-sided': the correlation is nonzero\u001b[39m\n",
      "\u001b[33m        * 'less': the correlation is negative (less than zero)\u001b[39m\n",
      "\u001b[33m        * 'greater':  the correlation is positive (greater than zero)\u001b[39m\n",
      "\n",
      "\u001b[33m        .. versionadded:: 1.9.0\u001b[39m\n",
      "\u001b[33m    method : ResamplingMethod, optional\u001b[39m\n",
      "\u001b[33m        Defines the method used to compute the p-value. If `method` is an\u001b[39m\n",
      "\u001b[33m        instance of `PermutationMethod`/`MonteCarloMethod`, the p-value is\u001b[39m\n",
      "\u001b[33m        computed using\u001b[39m\n",
      "\u001b[33m        `scipy.stats.permutation_test`/`scipy.stats.monte_carlo_test` with the\u001b[39m\n",
      "\u001b[33m        provided configuration options and other appropriate settings.\u001b[39m\n",
      "\u001b[33m        Otherwise, the p-value is computed as documented in the notes.\u001b[39m\n",
      "\n",
      "\u001b[33m        .. versionadded:: 1.11.0\u001b[39m\n",
      "\n",
      "\u001b[33m    Returns\u001b[39m\n",
      "\u001b[33m    -------\u001b[39m\n",
      "\u001b[33m    result : `~scipy.stats._result_classes.PearsonRResult`\u001b[39m\n",
      "\u001b[33m        An object with the following attributes:\u001b[39m\n",
      "\n",
      "\u001b[33m        statistic : float\u001b[39m\n",
      "\u001b[33m            Pearson product-moment correlation coefficient.\u001b[39m\n",
      "\u001b[33m        pvalue : float\u001b[39m\n",
      "\u001b[33m            The p-value associated with the chosen alternative.\u001b[39m\n",
      "\n",
      "\u001b[33m        The object has the following method:\u001b[39m\n",
      "\n",
      "\u001b[33m        confidence_interval(confidence_level, method)\u001b[39m\n",
      "\u001b[33m            This computes the confidence interval of the correlation\u001b[39m\n",
      "\u001b[33m            coefficient `statistic` for the given confidence level.\u001b[39m\n",
      "\u001b[33m            The confidence interval is returned in a ``namedtuple`` with\u001b[39m\n",
      "\u001b[33m            fields `low` and `high`. If `method` is not provided, the\u001b[39m\n",
      "\u001b[33m            confidence interval is computed using the Fisher transformation\u001b[39m\n",
      "\u001b[33m            [1]_. If `method` is an instance of `BootstrapMethod`, the\u001b[39m\n",
      "\u001b[33m            confidence interval is computed using `scipy.stats.bootstrap` with\u001b[39m\n",
      "\u001b[33m            the provided configuration options and other appropriate settings.\u001b[39m\n",
      "\u001b[33m            In some cases, confidence limits may be NaN due to a degenerate\u001b[39m\n",
      "\u001b[33m            resample, and this is typical for very small samples (~6\u001b[39m\n",
      "\u001b[33m            observations).\u001b[39m\n",
      "\n",
      "\u001b[33m    Raises\u001b[39m\n",
      "\u001b[33m    ------\u001b[39m\n",
      "\u001b[33m    ValueError\u001b[39m\n",
      "\u001b[33m        If `x` and `y` do not have length at least 2.\u001b[39m\n",
      "\n",
      "\u001b[33m    Warns\u001b[39m\n",
      "\u001b[33m    -----\u001b[39m\n",
      "\u001b[33m    `~scipy.stats.ConstantInputWarning`\u001b[39m\n",
      "\u001b[33m        Raised if an input is a constant array.  The correlation coefficient\u001b[39m\n",
      "\u001b[33m        is not defined in this case, so ``np.nan`` is returned.\u001b[39m\n",
      "\n",
      "\u001b[33m    `~scipy.stats.NearConstantInputWarning`\u001b[39m\n",
      "\u001b[33m        Raised if an input is \"nearly\" constant.  The array ``x`` is considered\u001b[39m\n",
      "\u001b[33m        nearly constant if ``norm(x - mean(x)) < 1e-13 * abs(mean(x))``.\u001b[39m\n",
      "\u001b[33m        Numerical errors in the calculation ``x - mean(x)`` in this case might\u001b[39m\n",
      "\u001b[33m        result in an inaccurate calculation of r.\u001b[39m\n",
      "\n",
      "\u001b[33m    See Also\u001b[39m\n",
      "\u001b[33m    --------\u001b[39m\n",
      "\u001b[33m    spearmanr : Spearman rank-order correlation coefficient.\u001b[39m\n",
      "\u001b[33m    kendalltau : Kendall's tau, a correlation measure for ordinal data.\u001b[39m\n",
      "\u001b[33m    :ref:`hypothesis_pearsonr` : Extended example\u001b[39m\n",
      "\n",
      "\u001b[33m    Notes\u001b[39m\n",
      "\u001b[33m    -----\u001b[39m\n",
      "\u001b[33m    The correlation coefficient is calculated as follows:\u001b[39m\n",
      "\n",
      "\u001b[33m    .. math::\u001b[39m\n",
      "\n",
      "\u001b[33m        r = \\frac{\\sum (x - m_x) (y - m_y)}\u001b[39m\n",
      "\u001b[33m                 {\\sqrt{\\sum (x - m_x)^2 \\sum (y - m_y)^2}}\u001b[39m\n",
      "\n",
      "\u001b[33m    where :math:`m_x` is the mean of the vector x and :math:`m_y` is\u001b[39m\n",
      "\u001b[33m    the mean of the vector y.\u001b[39m\n",
      "\n",
      "\u001b[33m    Under the assumption that x and y are drawn from\u001b[39m\n",
      "\u001b[33m    independent normal distributions (so the population correlation coefficient\u001b[39m\n",
      "\u001b[33m    is 0), the probability density function of the sample correlation\u001b[39m\n",
      "\u001b[33m    coefficient r is ([1]_, [2]_):\u001b[39m\n",
      "\n",
      "\u001b[33m    .. math::\u001b[39m\n",
      "\u001b[33m        f(r) = \\frac{{(1-r^2)}^{n/2-2}}{\\mathrm{B}(\\frac{1}{2},\\frac{n}{2}-1)}\u001b[39m\n",
      "\n",
      "\u001b[33m    where n is the number of samples, and B is the beta function.  This\u001b[39m\n",
      "\u001b[33m    is sometimes referred to as the exact distribution of r.  This is\u001b[39m\n",
      "\u001b[33m    the distribution that is used in `pearsonr` to compute the p-value when\u001b[39m\n",
      "\u001b[33m    the `method` parameter is left at its default value (None).\u001b[39m\n",
      "\u001b[33m    The distribution is a beta distribution on the interval [-1, 1],\u001b[39m\n",
      "\u001b[33m    with equal shape parameters a = b = n/2 - 1.  In terms of SciPy's\u001b[39m\n",
      "\u001b[33m    implementation of the beta distribution, the distribution of r is::\u001b[39m\n",
      "\n",
      "\u001b[33m        dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\u001b[39m\n",
      "\n",
      "\u001b[33m    The default p-value returned by `pearsonr` is a two-sided p-value. For a\u001b[39m\n",
      "\u001b[33m    given sample with correlation coefficient r, the p-value is\u001b[39m\n",
      "\u001b[33m    the probability that abs(r') of a random sample x' and y' drawn from\u001b[39m\n",
      "\u001b[33m    the population with zero correlation would be greater than or equal\u001b[39m\n",
      "\u001b[33m    to abs(r). In terms of the object ``dist`` shown above, the p-value\u001b[39m\n",
      "\u001b[33m    for a given r and length n can be computed as::\u001b[39m\n",
      "\n",
      "\u001b[33m        p = 2*dist.cdf(-abs(r))\u001b[39m\n",
      "\n",
      "\u001b[33m    When n is 2, the above continuous distribution is not well-defined.\u001b[39m\n",
      "\u001b[33m    One can interpret the limit of the beta distribution as the shape\u001b[39m\n",
      "\u001b[33m    parameters a and b approach a = b = 0 as a discrete distribution with\u001b[39m\n",
      "\u001b[33m    equal probability masses at r = 1 and r = -1.  More directly, one\u001b[39m\n",
      "\u001b[33m    can observe that, given the data x = [x1, x2] and y = [y1, y2], and\u001b[39m\n",
      "\u001b[33m    assuming x1 != x2 and y1 != y2, the only possible values for r are 1\u001b[39m\n",
      "\u001b[33m    and -1.  Because abs(r') for any sample x' and y' with length 2 will\u001b[39m\n",
      "\u001b[33m    be 1, the two-sided p-value for a sample of length 2 is always 1.\u001b[39m\n",
      "\n",
      "\u001b[33m    For backwards compatibility, the object that is returned also behaves\u001b[39m\n",
      "\u001b[33m    like a tuple of length two that holds the statistic and the p-value.\u001b[39m\n",
      "\n",
      "\u001b[33m    References\u001b[39m\n",
      "\u001b[33m    ----------\u001b[39m\n",
      "\u001b[33m    .. [1] \"Pearson correlation coefficient\", Wikipedia,\u001b[39m\n",
      "\u001b[33m           https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\u001b[39m\n",
      "\u001b[33m    .. [2] Student, \"Probable error of a correlation coefficient\",\u001b[39m\n",
      "\u001b[33m           Biometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.\u001b[39m\n",
      "\u001b[33m    .. [3] C. J. Kowalski, \"On the Effects of Non-Normality on the Distribution\u001b[39m\n",
      "\u001b[33m           of the Sample Product-Moment Correlation Coefficient\"\u001b[39m\n",
      "\u001b[33m           Journal of the Royal Statistical Society. Series C (Applied\u001b[39m\n",
      "\u001b[33m           Statistics), Vol. 21, No. 1 (1972), pp. 1-12.\u001b[39m\n",
      "\n",
      "\u001b[33m    Examples\u001b[39m\n",
      "\u001b[33m    --------\u001b[39m\n",
      "\u001b[33m    >>> import numpy as np\u001b[39m\n",
      "\u001b[33m    >>> from scipy import stats\u001b[39m\n",
      "\u001b[33m    >>> x, y = [1, 2, 3, 4, 5, 6, 7], [10, 9, 2.5, 6, 4, 3, 2]\u001b[39m\n",
      "\u001b[33m    >>> res = stats.pearsonr(x, y)\u001b[39m\n",
      "\u001b[33m    >>> res\u001b[39m\n",
      "\u001b[33m    PearsonRResult(statistic=-0.828503883588428, pvalue=0.021280260007523286)\u001b[39m\n",
      "\n",
      "\u001b[33m    To perform an exact permutation version of the test:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> rng = np.random.default_rng(7796654889291491997)\u001b[39m\n",
      "\u001b[33m    >>> method = stats.PermutationMethod(n_resamples=np.inf, random_state=rng)\u001b[39m\n",
      "\u001b[33m    >>> stats.pearsonr(x, y, method=method)\u001b[39m\n",
      "\u001b[33m    PearsonRResult(statistic=-0.828503883588428, pvalue=0.028174603174603175)\u001b[39m\n",
      "\n",
      "\u001b[33m    To perform the test under the null hypothesis that the data were drawn from\u001b[39m\n",
      "\u001b[33m    *uniform* distributions:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> method = stats.MonteCarloMethod(rvs=(rng.uniform, rng.uniform))\u001b[39m\n",
      "\u001b[33m    >>> stats.pearsonr(x, y, method=method)\u001b[39m\n",
      "\u001b[33m    PearsonRResult(statistic=-0.828503883588428, pvalue=0.0188)\u001b[39m\n",
      "\n",
      "\u001b[33m    To produce an asymptotic 90% confidence interval:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> res.confidence_interval(confidence_level=0.9)\u001b[39m\n",
      "\u001b[33m    ConfidenceInterval(low=-0.9644331982722841, high=-0.3460237473272273)\u001b[39m\n",
      "\n",
      "\u001b[33m    And for a bootstrap confidence interval:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> method = stats.BootstrapMethod(method='BCa', rng=rng)\u001b[39m\n",
      "\u001b[33m    >>> res.confidence_interval(confidence_level=0.9, method=method)\u001b[39m\n",
      "\u001b[33m    ConfidenceInterval(low=-0.9983163756488651, high=-0.22771001702132443)  # may vary\u001b[39m\n",
      "\n",
      "\u001b[33m    If N-dimensional arrays are provided, multiple tests are performed in a\u001b[39m\n",
      "\u001b[33m    single call according to the same conventions as most `scipy.stats` functions:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> rng = np.random.default_rng(2348246935601934321)\u001b[39m\n",
      "\u001b[33m    >>> x = rng.standard_normal((8, 15))\u001b[39m\n",
      "\u001b[33m    >>> y = rng.standard_normal((8, 15))\u001b[39m\n",
      "\u001b[33m    >>> stats.pearsonr(x, y, axis=0).statistic.shape  # between corresponding columns\u001b[39m\n",
      "\u001b[33m    (15,)\u001b[39m\n",
      "\u001b[33m    >>> stats.pearsonr(x, y, axis=1).statistic.shape  # between corresponding rows\u001b[39m\n",
      "\u001b[33m    (8,)\u001b[39m\n",
      "\n",
      "\u001b[33m    To perform all pairwise comparisons between slices of the arrays,\u001b[39m\n",
      "\u001b[33m    use standard NumPy broadcasting techniques. For instance, to compute the\u001b[39m\n",
      "\u001b[33m    correlation between all pairs of rows:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> stats.pearsonr(x[:, np.newaxis, :], y, axis=-1).statistic.shape\u001b[39m\n",
      "\u001b[33m    (8, 8)\u001b[39m\n",
      "\n",
      "\u001b[33m    There is a linear dependence between x and y if y = a + b*x + e, where\u001b[39m\n",
      "\u001b[33m    a,b are constants and e is a random error term, assumed to be independent\u001b[39m\n",
      "\u001b[33m    of x. For simplicity, assume that x is standard normal, a=0, b=1 and let\u001b[39m\n",
      "\u001b[33m    e follow a normal distribution with mean zero and standard deviation s>0.\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> rng = np.random.default_rng()\u001b[39m\n",
      "\u001b[33m    >>> s = 0.5\u001b[39m\n",
      "\u001b[33m    >>> x = stats.norm.rvs(size=500, random_state=rng)\u001b[39m\n",
      "\u001b[33m    >>> e = stats.norm.rvs(scale=s, size=500, random_state=rng)\u001b[39m\n",
      "\u001b[33m    >>> y = x + e\u001b[39m\n",
      "\u001b[33m    >>> stats.pearsonr(x, y).statistic\u001b[39m\n",
      "\u001b[33m    0.9001942438244763\u001b[39m\n",
      "\n",
      "\u001b[33m    This should be close to the exact value given by\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> 1/np.sqrt(1 + s**2)\u001b[39m\n",
      "\u001b[33m    0.8944271909999159\u001b[39m\n",
      "\n",
      "\u001b[33m    For s=0.5, we observe a high level of correlation. In general, a large\u001b[39m\n",
      "\u001b[33m    variance of the noise reduces the correlation, while the correlation\u001b[39m\n",
      "\u001b[33m    approaches one as the variance of the error goes to zero.\u001b[39m\n",
      "\n",
      "\u001b[33m    It is important to keep in mind that no correlation does not imply\u001b[39m\n",
      "\u001b[33m    independence unless (x, y) is jointly normal. Correlation can even be zero\u001b[39m\n",
      "\u001b[33m    when there is a very simple dependence structure: if X follows a\u001b[39m\n",
      "\u001b[33m    standard normal distribution, let y = abs(x). Note that the correlation\u001b[39m\n",
      "\u001b[33m    between x and y is zero. Indeed, since the expectation of x is zero,\u001b[39m\n",
      "\u001b[33m    cov(x, y) = E[x*y]. By definition, this equals E[x*abs(x)] which is zero\u001b[39m\n",
      "\u001b[33m    by symmetry. The following lines of code illustrate this observation:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> y = np.abs(x)\u001b[39m\n",
      "\u001b[33m    >>> stats.pearsonr(x, y)\u001b[39m\n",
      "\u001b[33m    PearsonRResult(statistic=-0.05444919272687482, pvalue=0.22422294836207743)\u001b[39m\n",
      "\n",
      "\u001b[33m    A non-zero correlation coefficient can be misleading. For example, if X has\u001b[39m\n",
      "\u001b[33m    a standard normal distribution, define y = x if x < 0 and y = 0 otherwise.\u001b[39m\n",
      "\u001b[33m    A simple calculation shows that corr(x, y) = sqrt(2/Pi) = 0.797...,\u001b[39m\n",
      "\u001b[33m    implying a high level of correlation:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> y = np.where(x < 0, x, 0)\u001b[39m\n",
      "\u001b[33m    >>> stats.pearsonr(x, y)\u001b[39m\n",
      "\u001b[33m    PearsonRResult(statistic=0.861985781588, pvalue=4.813432002751103e-149)\u001b[39m\n",
      "\n",
      "\u001b[33m    This is unintuitive since there is no dependence of x and y if x is larger\u001b[39m\n",
      "\u001b[33m    than zero which happens in about half of the cases if we sample x and y.\u001b[39m\n",
      "\n",
      "\u001b[33m    For a more detailed example, see :ref:`hypothesis_pearsonr`.\u001b[39m\n",
      "\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    xp = array_namespace(x, y)\n",
      "    x, y = xp_promote(x, y, force_floating=\u001b[38;5;28;01mTrue\u001b[39;00m, xp=xp)\n",
      "    dtype = x.dtype\n",
      "\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_numpy(xp) \u001b[38;5;28;01mand\u001b[39;00m method \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        method = \u001b[33m'invalid'\u001b[39m\n",
      "\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        x = xp.reshape(x, (-\u001b[32m1\u001b[39m,))\n",
      "        y = xp.reshape(y, (-\u001b[32m1\u001b[39m,))\n",
      "        axis = -\u001b[32m1\u001b[39m\n",
      "\n",
      "    axis_int = int(axis)\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m axis_int != axis:\n",
      "        \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m'`axis` must be an integer.'\u001b[39m)\n",
      "    axis = axis_int\n",
      "\n",
      "    \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "        np.broadcast_shapes(x.shape, y.shape)\n",
      "        \u001b[38;5;66;03m# For consistency with other `stats` functions, we need to\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# match the dimensionalities before looking at `axis`.\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# (Note: this is not the NEP 5 / gufunc order of operations;\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  see TestPearsonr::test_different_dimensionality for more information.)\u001b[39;00m\n",
      "        ndim = max(x.ndim, y.ndim)\n",
      "        x = xp.reshape(x, (\u001b[32m1\u001b[39m,) * (ndim - x.ndim) + x.shape)\n",
      "        y = xp.reshape(y, (\u001b[32m1\u001b[39m,) * (ndim - y.ndim) + y.shape)\n",
      "\n",
      "    \u001b[38;5;28;01mexcept\u001b[39;00m (ValueError, RuntimeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "        message = \u001b[33m'`x` and `y` must be broadcastable.'\u001b[39m\n",
      "        \u001b[38;5;28;01mraise\u001b[39;00m ValueError(message) \u001b[38;5;28;01mfrom\u001b[39;00m e\n",
      "\n",
      "    n = x.shape[axis]\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m n != y.shape[axis]:\n",
      "        \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m'`x` and `y` must have the same length along `axis`.'\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m2\u001b[39m:\n",
      "        \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m'`x` and `y` must have length at least 2.'\u001b[39m)\n",
      "\n",
      "    x = xp.moveaxis(x, axis, -\u001b[32m1\u001b[39m)\n",
      "    y = xp.moveaxis(y, axis, -\u001b[32m1\u001b[39m)\n",
      "    axis = -\u001b[32m1\u001b[39m\n",
      "\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m xp.isdtype(dtype, \u001b[33m\"complex floating\"\u001b[39m):\n",
      "        \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m'This function does not support complex data'\u001b[39m)\n",
      "\n",
      "    x = xp.astype(x, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "    y = xp.astype(y, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "    threshold = xp.finfo(dtype).eps ** \u001b[32m0.75\u001b[39m\n",
      "\n",
      "    \u001b[38;5;66;03m# If an input is constant, the correlation coefficient is not defined.\u001b[39;00m\n",
      "    const_x = xp.all(x == x[..., \u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m], axis=-\u001b[32m1\u001b[39m)\n",
      "    const_y = xp.all(y == y[..., \u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m], axis=-\u001b[32m1\u001b[39m)\n",
      "    const_xy = const_x | const_y\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m xp.any(const_xy):\n",
      "        msg = (\u001b[33m\"An input array is constant; the correlation coefficient \"\u001b[39m\n",
      "               \u001b[33m\"is not defined.\"\u001b[39m)\n",
      "        warnings.warn(stats.ConstantInputWarning(msg), stacklevel=\u001b[32m2\u001b[39m)\n",
      "        x = xp.where(const_x[..., xp.newaxis], xp.nan, x)\n",
      "        y = xp.where(const_y[..., xp.newaxis], xp.nan, y)\n",
      "\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m isinstance(method, PermutationMethod):\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m statistic(y, axis):\n",
      "            statistic, _ = pearsonr(x, y, axis=axis, alternative=alternative)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m statistic\n",
      "\n",
      "        res = permutation_test((y,), statistic, permutation_type=\u001b[33m'pairings'\u001b[39m,\n",
      "                               axis=axis, alternative=alternative, **method._asdict())\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m PearsonRResult(statistic=res.statistic, pvalue=res.pvalue, n=n,\n",
      "                              alternative=alternative, x=x, y=y, axis=axis)\n",
      "    \u001b[38;5;28;01melif\u001b[39;00m isinstance(method, MonteCarloMethod):\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m statistic(x, y, axis):\n",
      "            statistic, _ = pearsonr(x, y, axis=axis, alternative=alternative)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m statistic\n",
      "\n",
      "        \u001b[38;5;66;03m# `monte_carlo_test` accepts an `rvs` tuple of callables, not an `rng`\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# If the user specified an `rng`, replace it with the appropriate callables\u001b[39;00m\n",
      "        method = method._asdict()\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m (rng := method.pop(\u001b[33m'rng'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# goo-goo g'joob\u001b[39;00m\n",
      "            rng = np.random.default_rng(rng)\n",
      "            method[\u001b[33m'rvs'\u001b[39m] = rng.normal, rng.normal\n",
      "\n",
      "        res = monte_carlo_test((x, y,), statistic=statistic, axis=axis,\n",
      "                               alternative=alternative, **method)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m PearsonRResult(statistic=res.statistic, pvalue=res.pvalue, n=n,\n",
      "                              alternative=alternative, x=x, y=y, axis=axis)\n",
      "    \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'invalid'\u001b[39m:\n",
      "        message = \u001b[33m'`method` must be `None` if arguments are not NumPy arrays.'\u001b[39m\n",
      "        \u001b[38;5;28;01mraise\u001b[39;00m ValueError(message)\n",
      "    \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        message = (\u001b[33m'`method` must be an instance of `PermutationMethod`,'\u001b[39m\n",
      "                   \u001b[33m'`MonteCarloMethod`, or None.'\u001b[39m)\n",
      "        \u001b[38;5;28;01mraise\u001b[39;00m ValueError(message)\n",
      "\n",
      "    xmean = xp.mean(x, axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "    ymean = xp.mean(y, axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "    xm = x - xmean\n",
      "    ym = y - ymean\n",
      "\n",
      "    \u001b[38;5;66;03m# scipy.linalg.norm(xm) avoids premature overflow when xm is e.g.\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# [-5e210, 5e210, 3e200, -3e200]\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# but not when `axis` is provided, so scale manually. scipy.linalg.norm\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# also raises an error with NaN input rather than returning NaN, so\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# use np.linalg.norm.\u001b[39;00m\n",
      "    xmax = xp.max(xp.abs(xm), axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "    ymax = xp.max(xp.abs(ym), axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "    \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(invalid=\u001b[33m'ignore'\u001b[39m, divide=\u001b[33m'ignore'\u001b[39m):\n",
      "        normxm = xmax * xp_vector_norm(xm/xmax, axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "        normym = ymax * xp_vector_norm(ym/ymax, axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "    nconst_x = xp.any(normxm < threshold*xp.abs(xmean), axis=axis)\n",
      "    nconst_y = xp.any(normym < threshold*xp.abs(ymean), axis=axis)\n",
      "    nconst_xy = nconst_x | nconst_y\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m xp.any(nconst_xy & (~const_xy)):\n",
      "        \u001b[38;5;66;03m# If all the values in x (likewise y) are very close to the mean,\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# the loss of precision that occurs in the subtraction xm = x - xmean\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# might result in large errors in r.\u001b[39;00m\n",
      "        msg = (\u001b[33m\"An input array is nearly constant; the computed \"\u001b[39m\n",
      "               \u001b[33m\"correlation coefficient may be inaccurate.\"\u001b[39m)\n",
      "        warnings.warn(stats.NearConstantInputWarning(msg), stacklevel=\u001b[32m2\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(invalid=\u001b[33m'ignore'\u001b[39m, divide=\u001b[33m'ignore'\u001b[39m):\n",
      "        r = xp.vecdot(xm / normxm, ym / normym, axis=axis)\n",
      "\n",
      "    \u001b[38;5;66;03m# Presumably, if abs(r) > 1, then it is only some small artifact of\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# floating point arithmetic.\u001b[39;00m\n",
      "    r = xp.clip(r, -\u001b[32m1.\u001b[39m, \u001b[32m1.\u001b[39m)\n",
      "    r = xpx.at(r, const_xy).set(xp.nan)\n",
      "\n",
      "    \u001b[38;5;66;03m# Make sure we return exact 1.0 or -1.0 values for n == 2 case as promised\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# in the docs.\u001b[39;00m\n",
      "    \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m2\u001b[39m:\n",
      "        r = xp.round(r)\n",
      "        one = xp.asarray(\u001b[32m1\u001b[39m, dtype=dtype)\n",
      "        pvalue = xp.where(xp.asarray(xp.isnan(r)), xp.nan*one, one)\n",
      "    \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "        \u001b[38;5;66;03m# As explained in the docstring, the distribution of `r` under the null\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# hypothesis is the beta distribution on (-1, 1) with a = b = n/2 - 1.\u001b[39;00m\n",
      "        ab = xp.asarray(n/\u001b[32m2\u001b[39m - \u001b[32m1\u001b[39m)\n",
      "        dist = _SimpleBeta(ab, ab, loc=-\u001b[32m1\u001b[39m, scale=\u001b[32m2\u001b[39m)\n",
      "        pvalue = _get_pvalue(r, dist, alternative, xp=xp)\n",
      "\n",
      "    r = r[()] \u001b[38;5;28;01mif\u001b[39;00m r.ndim == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m r\n",
      "    pvalue = pvalue[()] \u001b[38;5;28;01mif\u001b[39;00m pvalue.ndim == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m pvalue\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m PearsonRResult(statistic=r, pvalue=pvalue, n=n,\n",
      "                          alternative=alternative, x=x, y=y, axis=axis)\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\paul.carvalho\\documents\\data science\\python\\linear-algebra\\venv\\lib\\site-packages\\scipy\\stats\\_stats_py.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "# Exercise 4-3\n",
    "# import the function\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# inspect the source code\n",
    "??pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24defe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My function took 50.03 ms\n",
      "   pearsonr took 35.60 ms\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4-4\n",
    "# a bare-bones correlation function\n",
    "def rho(x,y):\n",
    "  xm = x-np.mean(x)\n",
    "  ym = y-np.mean(y)\n",
    "  n  = np.dot(xm,ym)\n",
    "  d  = np.linalg.norm(xm) * np.linalg.norm(ym)\n",
    "  return n/d\n",
    "\n",
    "# import the time library\n",
    "import time\n",
    "\n",
    "# experiment parameters\n",
    "numIters  = 1000\n",
    "varLength =  500\n",
    "\n",
    "# clock custom-written function\n",
    "tic = time.time()\n",
    "for i in range(numIters):\n",
    "  x = np.random.randn(varLength,2)\n",
    "  rho(x[:,0],x[:,1])\n",
    "t1 = time.time() - tic\n",
    "\n",
    "# now for numpy's corrcoef function\n",
    "tic = time.time()\n",
    "for i in range(numIters):\n",
    "  x = np.random.randn(varLength,2)\n",
    "  pearsonr(x[:,0],x[:,1])\n",
    "t2 = time.time() - tic\n",
    "\n",
    "# print the results!\n",
    "# Note: time() returns seconds, so I multiply by 1000 for ms\n",
    "print(f'My function took {t1*1000:.2f} ms')\n",
    "print(f'   pearsonr took {t2*1000:.2f} ms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
